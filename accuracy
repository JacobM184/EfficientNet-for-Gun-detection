  model.eval()
  test_acc = 0.0
  count=0
  timestamp1 = time.time()
  for samples, labels in test_loader:
    with torch.no_grad():
        count+=1
        if (device!='cpu'):
            samples, labels = samples.cuda(), labels.cuda()





        output = model(samples)

        # calculate accuracy
        pred = torch.argmax(output, dim=1)
        correct = pred.eq(labels)
        test_acc += torch.mean(correct.float())

  timestamp2 = time.time()

  print( "This took %.2f seconds" % (timestamp2 - timestamp1))
  print( "time per imag= %.3f" %( (timestamp2 - timestamp1)/(count*10)))
  print('Accuracy of the network on {} test images: {}%'.format(count*10, round(test_acc.item()*100.0/len(test_loader), 2)))
